<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta name="generator" content="Hugo 0.51" />

  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="author" content="a-coder">
  <meta property="og:url" content="https://joshua0x.github.io/post/logging_safety/">

  <title>python logging  安全 - a-coder</title>
  <meta property="og:title" content="python logging  安全 - a-coder">
  <meta property="og:type" content="article">
  <meta name="description" content="">

  <link href="https://fonts.googleapis.com/css?family=Arvo|Permanent+Marker" rel="stylesheet">
  <link rel="stylesheet" href="/css/flexboxgrid.min.css">
  <link rel="stylesheet" href="/css/index.css">

  <link rel="stylesheet" href="/css/github-md.css">
  <link rel="stylesheet" href="/css/highlight/tomorrow-night.css">
  <link href="/index.xml" rel="alternate" type="application/rss+xml" title="a-coder">

  
</head>


  <body>
    <article class="post">
      <div class="row">
        <div class="col-xs-12 col-md-8 col-md-offset-2 col-lg-6 col-lg-offset-3">
          <a href="https://joshua0x.github.io">
            <div class="head-line"></div>
          </a>
          <header class="post-header">
            <h1 class="post-title">python logging  安全</h1>
            <div class="row">
              <div class="col-xs-6">
                <time class="post-date" datetime="2019-01-06 13:40:49 CST">
                  06 Jan 2019
                </time>
              </div>
              <div class="col-xs-6">
                <div class="post-author">
                  <a target="_blank" href="https://joshua0x.github.io">@a-coder</a>
                </div>
              </div>
            </div>
          </header>
    
          <div class="post-content markdown-body">
            

<h2 id="线程安全">线程安全</h2>

<h3 id="测试">测试</h3>

<p>按照官方doc , 在多线程环境下访问模块shared data object  ,以及handler写入文件系统时都通过加锁保证原子写入</p>

<p>在进程内多个相同参数调用  logging.getLogger  会返回同1个对象</p>

<p>可以用 如下 代码测试  ， 注意由于imported modules 是进程级别的, 下面的多线程环境重复IMPORT  不会导致重复IMPORT</p>

<pre><code>import  threading
import  time
def  worker():
    import logging as  lg
    k = lg.getLogger('a')
    print   id(lg),id(k)
    print  '\n'
t =  threading.Thread(target = worker)
t.start()
t =  threading.Thread(target = worker)
t.start()
</code></pre>

<h3 id="源码分析">源码分析</h3>

<p>为保证线程安全  , 源码中  主要通过  threading.Rlock 保护  2类 对象:</p>

<p>a.  module level   object</p>

<p>b. 文件IO</p>

<h2 id="多进程写日志">多进程写日志</h2>

<p>通过logging  filehandler , 多进程环境下写入相同的日志文件 是安全的吗？</p>

<p>通过如下代码进行测试，在t_str 超过 8k后  统计&rsquo;test&rsquo; 文件每行长度 发现不一致 ,即写入发送了截断冲突</p>

<p>查阅 logging 源码  发现  FileHandler 是以&rsquo;a&rsquo; 模式打开文件,按照《The Linux Programming inTerface》：<br />
O_APPEND  模式 可以保证 每次写入前SEEK_END ，而且为原子操作 (每次系统调用由kernel保证为原子操作)；存在例外为 PIPE,FIFO 在操作时，有PIPE_BUF 的限制,</p>

<p>[ref1] 中解释为因为PIPE_BUF 限制而出现此问题,但是测试代码写的是REGULAR  FILE ，应该不是此问题.<br />
[ref3] 中给出的MPFileLogHandler ，经过测试是进程安全的,</p>

<p>是否因为 PYTHON  OPEN 函数 与    OS.OPEN 实现不同呢?   还有待验证</p>

<pre><code>	# coding :utf-8
	from multiprocessing import  Pool
	import logging
	import datetime  
	import os 
	class MPFileLogHandler(logging.Handler):
	    def __init__(self, file_path):      

		self._fd = os.open(file_path, os.O_WRONLY | os.O_CREAT | os.O_APPEND)
		logging.Handler.__init__(self)

	    def emit(self, record):    

		msg = &quot;{}\n&quot;.format(self.format(record))
		os.write(self._fd, msg.encode('utf-8'))
	def process_log(p_off):
	    #logger_handler = MPFileLogHandler('test')
	    logger_handler = logging.FileHandler('test')
	    logger = logging.getLogger('test')
	    logger.addHandler(logger_handler)
	    logger.setLevel(logging.DEBUG)
	    for x in range(0, 200):   

		d = datetime.datetime.now()
		t_str = 'test' *10 # 
		logger.info('{}:{}:p_off({}):pid({})'.format(t_str, d.strftime('%Y-%m-%d %H:%M:%S'), p_off, os.getpid()))

	#process_log(1)
	if __name__ == '__main__':
	    p = Pool(4)
	    for i in range(32):   

		p.apply_async(process_log, args=(i,))
	    print  'waiting.....'
	    p.close()
	    p.join()

```	 



##   日志分割
下面考虑多进程写系统日志   日志分割时的安全性
对于每条日志  ，处理流程如下：
handle 函数是handler基类的函数，其他的Handler实现直接或者间接地继承该类
</code></pre>

<pre><code>def handle(self, record):
    &quot;&quot;&quot;
    Conditionally emit the specified logging record.

    Emission depends on filters which may have been added to the handler.
    Wrap the actual emission of the record with acquisition/release of
    the I/O thread lock. Returns whether the filter passed the record for
    emission.
    &quot;&quot;&quot;
    rv = self.filter(record)
    if rv:
        self.acquire()
        try:
            self.emit(record)
        finally:
            self.release()
    return rv
</code></pre>

<pre><code>


###   TimedRotatingFileHandler 
TimedRotatingFileHandler  按照时间分割日志文件 ，在多进程环境下 对同1个日志处理时  安全吗？
简化的代码如下：

```python

	def doRollover(self):
	    if self.stream:
		self.stream.close()
		self.stream = None
	    # get the time that this sequence started at and make it a TimeTuple
	    dfn = self.baseFilename + &quot;.&quot; + time.strftime(self.suffix, timeTuple)
	    if os.path.exists(dfn):
		os.remove(dfn)
	    if os.path.exists(self.baseFilename):
		os.rename(self.baseFilename, dfn)
	    self.rolloverAt = newRolloverAt

</code></pre>

<p>显然在多进程都调用  时  存在 其他进程  删除 已经 完成分割进程的日志文件的可能</p>

<h3 id="timedrotatingfilehandler-mp">TimedRotatingFileHandler_MP</h3>

<p>关键函数如下</p>

<pre><code>	    def emit(self, record):
		&quot;&quot;&quot;
		Emit a record.

		Output the record to the file, catering for rollover as described
		in doRollover().
		
		For multiprocess, we use file lock. Any better method ?
		&quot;&quot;&quot;
		try:
		    if self.shouldRollover(record):
			self.doRollover()
		    FileLock = self._lock_dir + '/' + os.path.basename(self.baseFilename) + '.' + record.levelname
		    f = open(FileLock, &quot;w+&quot;)
		    fcntl.flock(f.fileno(), fcntl.LOCK_EX)
		    FileHandler_MP.emit(self, record)
		    fcntl.flock(f.fileno(), fcntl.LOCK_UN)
		    f.close()
		except (KeyboardInterrupt, SystemExit):
		    raise
		except:
		    self.handleError(record)
</code></pre>

<p>文件分割阶段  依旧存在  TimedRotatingFileHandler 中所述问题</p>

<h2 id="concurrentloghandler">ConcurrentLogHandler</h2>

<p>ConcurrentLogHandler  重写了基类 Handler  acquire 方法  ,  按照文件大小分割
通过文件的 排他锁保证单个进程的分割是原子的，下个进程在判断是否需要分割时 ，对已经分割完的文件进行判断
可见可以安全地分割文件</p>

<pre><code>	    def acquire(self):
		&quot;&quot;&quot; Acquire thread and file locks.  Re-opening log for 'degraded' mode.
		&quot;&quot;&quot;
		# handle thread lock
		Handler.acquire(self)
		# Issue a file lock.  (This is inefficient for multiple active threads
		# within a single process. But if you're worried about high-performance,
		# you probably aren't using this log handler.)
		if self.stream_lock:
		    # If stream_lock=None, then assume close() was called or something
		    # else weird and ignore all file-level locks.
		    if self.stream_lock.closed:
			# Daemonization can close all open file descriptors, see
			# https://bugzilla.redhat.com/show_bug.cgi?id=952929
			# Try opening the lock file again.  Should we warn() here?!?
			try:
			    self._open_lockfile()
			except Exception:
			    self.handleError(NullLogRecord())
			    # Don't try to open the stream lock again
			    self.stream_lock = None
			    return
		    lock(self.stream_lock, LOCK_EX)
		# Stream will be opened as part by FileHandler.emit()

</code></pre>

<h2 id="refs">refs</h2>

<p>[0]<a href="https://stackoverflow.com/questions/12111127/how-standard-specify-atomic-write-to-regular-filenot-pipe-or-fifo">https://stackoverflow.com/questions/12111127/how-standard-specify-atomic-write-to-regular-filenot-pipe-or-fifo</a></p>

<p>[1]<a href="https://manjusaka.itscoder.com/2018/02/23/logging-process-safe/">https://manjusaka.itscoder.com/2018/02/23/logging-process-safe/</a></p>

<p>[3]<a href="https://www.u3v3.com/ar/1330">https://www.u3v3.com/ar/1330</a></p>

          </div>
          
        </div>
      </div>
    </article>

    <script src="/js/highlight.pack.js"></script>
<script>
  hljs.initHighlightingOnLoad();
</script>

  </body>
</html>
